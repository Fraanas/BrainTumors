{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fraanas/BrainTumors/blob/test/imageGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2025-05-30T09:05:01.584344Z",
          "start_time": "2025-05-30T09:05:01.448824Z"
        },
        "id": "initial_id"
      },
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "import os\n",
        "import zipfile\n",
        "import gdown\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T\n",
        "from torch import optim\n",
        "from torchvision import utils"
      ],
      "outputs": [],
      "execution_count": 1
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "741445b56d745f54",
        "outputId": "6108c94e-a964-4613-f011-0a402f4849fd"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data already exists. I'm skipping the downloading and unpacking.\n"
          ]
        }
      ],
      "execution_count": 2,
      "source": [
        "def extract_gdrive_file(folder_id, output_path):\n",
        "    '''\n",
        "    Download and extract a ZIP file from Google Drive.\n",
        "    Parameters:\n",
        "    - folder_id (str): The unique ID of the file from G Drive link.\n",
        "    - output_path (str): The path where the files will be extracted.\n",
        "    '''\n",
        "    # check whether the data already exists\n",
        "    if os.path.exists(output_path) and len(os.listdir(output_path)) > 0:\n",
        "        print(\"Data already exists. I'm skipping the downloading and unpacking.\")\n",
        "        return\n",
        "\n",
        "    # create file for extracted files, if not existed\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "\n",
        "    # download file from Google Drive\n",
        "    zip_url = f\"https://drive.google.com/uc?export=download&id={folder_id}\"\n",
        "    zip_filename = os.path.join(output_path, \"brain_tumors_img.zip\")\n",
        "    print(f\"Downloading file from Google Drive to {zip_filename}...\")\n",
        "    gdown.download(zip_url, zip_filename, quiet=False)\n",
        "\n",
        "    # extract the file to output path\n",
        "    print(f\"Unzipping file: {zip_filename}...\")\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_filename, \"r\") as zip_ref:\n",
        "            zip_ref.extractall(output_path)\n",
        "        print(\"Unzipping of the file is complete!\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(\"Error: The downloaded file is not a valid ZIP archive.\")\n",
        "        return\n",
        "\n",
        "    # delete zip file after extraction\n",
        "    os.remove(zip_filename)\n",
        "    print(\"ZIP file has been removed!\")\n",
        "\n",
        "    # Remove the _MACOSX folder if exists\n",
        "    macosx_path = os.path.join(output_path, '__MACOSX')\n",
        "    if os.path.exists(macosx_path):\n",
        "        shutil.rmtree(macosx_path)\n",
        "        print(\"_MACOSX folder has been removed!\")\n",
        "\n",
        "    # Remove .DS_Store files from the extracted folders\n",
        "    for root, dirs, files in os.walk(output_path):\n",
        "        for file in files:\n",
        "            if file == \".DS_Store\":\n",
        "                file_path = os.path.join(root, file)\n",
        "                os.remove(file_path)\n",
        "                print(f\"Removed file: {file_path}\")\n",
        "\n",
        "\n",
        "\n",
        "FOLDER_ID = \"1xHeIOOHUFlnTxuSJzwuoVMmb3iz-oHlB\"\n",
        "OUTPUT_PATH = \"./data/tumors\"\n",
        "extract_gdrive_file(FOLDER_ID, OUTPUT_PATH)"
      ],
      "id": "741445b56d745f54"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:15.960604Z",
          "start_time": "2025-05-30T08:30:14.210021Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85c33c5accd24050",
        "outputId": "3d24568a-25a6-45a5-9e64-9dafd112cc61"
      },
      "cell_type": "code",
      "source": [
        "# directories for images\n",
        "TRAIN_DIR = Path('data/tumors/brain_tumors_img/Training')\n",
        "TEST_DIR = Path('data/tumors/brain_tumors_img/Testing')\n",
        "TRAIN_GAN_DIR = Path('data/tumors/brain_tumors_img/TrainingGAN')\n",
        "\n",
        "os.makedirs(TRAIN_GAN_DIR, exist_ok=True)\n",
        "\n",
        "def copy_contents(src1,src2, dst):\n",
        "    if not os.path.exists(dst):\n",
        "        os.makedirs(dst)\n",
        "        print(f'Folder {dst} has been created.')\n",
        "    else:\n",
        "        print(f'Folder {dst} already exists.')\n",
        "\n",
        "    def copy_images(src):\n",
        "        for image in os.listdir(src):\n",
        "            s = os.path.join(src, image)\n",
        "            d = os.path.join(dst, image)\n",
        "            if os.path.isdir(s):\n",
        "                shutil.copytree(s, d, dirs_exist_ok=True)\n",
        "                print(f\"Copied folder: {s} -> {d}\")\n",
        "            else:\n",
        "                shutil.copy2(s, d)\n",
        "                print(f\"Copied images: {s} -> {d}\")\n",
        "\n",
        "    # Merge images from training dataset and testing dataset folders\n",
        "    copy_images(src1)\n",
        "    copy_images(src2)\n",
        "    print(f\"Images from: {src1} and {src2} are merged and saved in {dst}\")\n",
        "\n",
        "copy_contents(TRAIN_DIR, TEST_DIR, TRAIN_GAN_DIR)"
      ],
      "id": "85c33c5accd24050",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder data/tumors/brain_tumors_img/TrainingGAN already exists.\n",
            "Copied folder: data/tumors/brain_tumors_img/Training/notumor -> data/tumors/brain_tumors_img/TrainingGAN/notumor\n",
            "Copied folder: data/tumors/brain_tumors_img/Training/meningioma -> data/tumors/brain_tumors_img/TrainingGAN/meningioma\n",
            "Copied folder: data/tumors/brain_tumors_img/Training/pituitary -> data/tumors/brain_tumors_img/TrainingGAN/pituitary\n",
            "Copied folder: data/tumors/brain_tumors_img/Training/glioma -> data/tumors/brain_tumors_img/TrainingGAN/glioma\n",
            "Copied folder: data/tumors/brain_tumors_img/Testing/notumor -> data/tumors/brain_tumors_img/TrainingGAN/notumor\n",
            "Copied folder: data/tumors/brain_tumors_img/Testing/meningioma -> data/tumors/brain_tumors_img/TrainingGAN/meningioma\n",
            "Copied folder: data/tumors/brain_tumors_img/Testing/pituitary -> data/tumors/brain_tumors_img/TrainingGAN/pituitary\n",
            "Copied folder: data/tumors/brain_tumors_img/Testing/glioma -> data/tumors/brain_tumors_img/TrainingGAN/glioma\n",
            "Images from: data/tumors/brain_tumors_img/Training and data/tumors/brain_tumors_img/Testing are merged and saved in data/tumors/brain_tumors_img/TrainingGAN\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:16.747527Z",
          "start_time": "2025-05-30T08:30:16.745701Z"
        },
        "id": "cc2f77ce8d6807ee"
      },
      "cell_type": "code",
      "source": [
        "nb_gpu = 1\n",
        "image_size = 64 # 64 is better than\n",
        "nb_channels = 3 # For RGB images\n",
        "batch_size = 64\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)"
      ],
      "id": "cc2f77ce8d6807ee",
      "outputs": [],
      "execution_count": 4
    },
    {
      "metadata": {
        "id": "da1e6123af10b6b7"
      },
      "cell_type": "markdown",
      "source": [
        "- **nb_gpu = 1** -> number of GPUs\n",
        "- **image_size = 64** -> it's size of image, which performs better with DCGAN network architecture than 224x224\n",
        "- **nb_channels = 3** -> number of channels (RGB = 3 channels)\n",
        "- **batch_size = 64** -> size of the batch\n",
        "- **stats** -> used for normalize the images"
      ],
      "id": "da1e6123af10b6b7"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:17.235455Z",
          "start_time": "2025-05-30T08:30:17.206094Z"
        },
        "id": "73c026e0fdcb3555"
      },
      "cell_type": "code",
      "source": [
        "train_dataset = ImageFolder(TRAIN_GAN_DIR, transform=T.Compose([\n",
        "    T.Resize((image_size, image_size)),\n",
        "    T.CenterCrop(image_size),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(*stats),\n",
        "]))\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True, num_workers=2,\n",
        "                              pin_memory=True)"
      ],
      "id": "73c026e0fdcb3555",
      "outputs": [],
      "execution_count": 5
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:17.704105Z",
          "start_time": "2025-05-30T08:30:17.701366Z"
        },
        "id": "5d656e1016abf1d8"
      },
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU or MPS if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\")\n",
        "    else:\n",
        "         return torch.device(\"cpu\")\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensors to chosen device\"\"\"\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "id": "5d656e1016abf1d8",
      "outputs": [],
      "execution_count": 6
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:18.174069Z",
          "start_time": "2025-05-30T08:30:18.169140Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66af9e1ba72af00f",
        "outputId": "3f2597e7-a54d-4ecd-fff7-7eef3bb29e3f"
      },
      "cell_type": "code",
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "id": "66af9e1ba72af00f",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": 7
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:18.630971Z",
          "start_time": "2025-05-30T08:30:18.628985Z"
        },
        "id": "f827c7fbe2b05085"
      },
      "cell_type": "code",
      "source": [
        "train_dataloader = DeviceDataLoader(train_dataloader, device)"
      ],
      "id": "f827c7fbe2b05085",
      "outputs": [],
      "execution_count": 8
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:19.091377Z",
          "start_time": "2025-05-30T08:30:19.089623Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "438414e1601454f1",
        "outputId": "81e97169-e277-4178-a89a-6150926bbf7e"
      },
      "cell_type": "code",
      "source": [
        "print(f'Number of downloaded images: {len(train_dataset)}')"
      ],
      "id": "438414e1601454f1",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of downloaded images: 7023\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "metadata": {
        "id": "5b3b20849fdc879d"
      },
      "cell_type": "markdown",
      "source": [
        "# GAN"
      ],
      "id": "5b3b20849fdc879d"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:19.553256Z",
          "start_time": "2025-05-30T08:30:19.551407Z"
        },
        "id": "85c008e176c7363b"
      },
      "cell_type": "code",
      "source": [
        "# Size of z latent vector (i.e. size of generator input), same size as described in the DCGAN paper\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 100\n",
        "\n",
        "# Learning rate for optimizers, same value as described in the DCGAN paper\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparameter for Adam optimizers, same value as described in the DCGAN paper\n",
        "beta1 = 0.5"
      ],
      "id": "85c008e176c7363b",
      "outputs": [],
      "execution_count": 10
    },
    {
      "metadata": {
        "id": "e673fea0a9bfe2bd"
      },
      "cell_type": "markdown",
      "source": [
        "The following function will allow us to initialize the weights of our generator's & discriminator's convolutional layers with a normal distribution, and batch normalization layers with a mean of 1.0 and bias to 0."
      ],
      "id": "e673fea0a9bfe2bd"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:20.025074Z",
          "start_time": "2025-05-30T08:30:20.022893Z"
        },
        "id": "c042cd4343a23d50"
      },
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "# We will use it on our networks when they will be initialized."
      ],
      "id": "c042cd4343a23d50",
      "outputs": [],
      "execution_count": 11
    },
    {
      "metadata": {
        "id": "b4a1eb73bc2bb08"
      },
      "cell_type": "markdown",
      "source": [
        "## Generator Network"
      ],
      "id": "b4a1eb73bc2bb08"
    },
    {
      "metadata": {
        "id": "b426d5643feeda1c"
      },
      "cell_type": "markdown",
      "source": [
        " The generator architecture is designed to take a random noise vector z (nz=100) as input and transform it into a (3x64x64) image, which is better to generate than (3x224x224) because of computation cost"
      ],
      "id": "b426d5643feeda1c"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:20.475798Z",
          "start_time": "2025-05-30T08:30:20.472909Z"
        },
        "id": "8f6eadb3b3b0adb3"
      },
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nb_gpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.nb_gpu = nb_gpu\n",
        "        self.main = nn.Sequential(\n",
        "\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. '(ngf*8) x 4 x 4'\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. '(ngf*4) x 8 x 8'\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. '(ngf*2) x 16 x 16'\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. '(ngf*1) x 32 x 32'\n",
        "\n",
        "            nn.ConvTranspose2d(ngf, nb_channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. '(nb_channels) x 64 x 64' (3x63x64)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        ""
      ],
      "id": "8f6eadb3b3b0adb3",
      "outputs": [],
      "execution_count": 12
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:20.941034Z",
          "start_time": "2025-05-30T08:30:20.922916Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bbce27c1a2c9f60",
        "outputId": "6d897032-6125-4c6f-d33a-96c07311cf38"
      },
      "cell_type": "code",
      "source": [
        "# create Generator\n",
        "netG = Generator(nb_gpu).to(device)\n",
        "\n",
        "if (device.type == 'cuda' or device.type == 'mps') and (nb_gpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(nb_gpu)))\n",
        "\n",
        "# apply the 'weights_init' function to randomly initialize all weights\n",
        "netG.apply(weights_init)\n",
        "print(netG)"
      ],
      "id": "9bbce27c1a2c9f60",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "metadata": {
        "id": "285b493681c083dc"
      },
      "cell_type": "markdown",
      "source": [
        "## Discriminator Network\n"
      ],
      "id": "285b493681c083dc"
    },
    {
      "metadata": {
        "id": "c2de380edb7eb9da"
      },
      "cell_type": "markdown",
      "source": [
        "The discriminator takes an input image of size (3x64x64) and outputs a probability, indicating if the input image is real (1) or fake (0)."
      ],
      "id": "c2de380edb7eb9da"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:21.391575Z",
          "start_time": "2025-05-30T08:30:21.388910Z"
        },
        "id": "e525a335de2a04"
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, nb_gpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.nb_gpu = nb_gpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input: (nb_channels) x 64 x 64\n",
        "\n",
        "            nn.Conv2d(nb_channels, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            # state size: (ndf) x 32 x 32\n",
        "\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            # state size: (ndf*2) x 16 x 16\n",
        "\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            # state size: (ndf*4) x 8 x 8\n",
        "\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            # state size: (ndf*8) x 4 x 4\n",
        "\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid() # gives output in range 0 to 1 to classification\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "id": "e525a335de2a04",
      "outputs": [],
      "execution_count": 14
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:21.853276Z",
          "start_time": "2025-05-30T08:30:21.839758Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc513cd77f81ed51",
        "outputId": "087d3398-5e18-4f22-d7a3-8ca6dbc3a315"
      },
      "cell_type": "code",
      "source": [
        "# create Discriminator\n",
        "netD = Discriminator(nb_gpu).to(device)\n",
        "\n",
        "if (device.type == 'cuda' or device.type == 'mps') and (nb_gpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(nb_gpu)))\n",
        "\n",
        "# apply the 'weights_init' function to randomly initialize all weights\n",
        "netD.apply(weights_init)\n",
        "print(netD)\n",
        ""
      ],
      "id": "bc513cd77f81ed51",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (6): Dropout(p=0.3, inplace=False)\n",
            "    (7): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (10): Dropout(p=0.3, inplace=False)\n",
            "    (11): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (14): Dropout(p=0.3, inplace=False)\n",
            "    (15): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (16): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "execution_count": 15
    },
    {
      "metadata": {
        "id": "64cd9c0f2d91776d"
      },
      "cell_type": "markdown",
      "source": [
        "## Loss"
      ],
      "id": "64cd9c0f2d91776d"
    },
    {
      "metadata": {
        "id": "dee6f69b7be9cb0e"
      },
      "cell_type": "markdown",
      "source": [
        "The adversarial loss V(D, G) can be approximated using the **Binary Cross Entropy (BCE)** loss function, which is commonly used for GANs because it measures the binary cross-entropy between the discriminatorâ€™s output (probability) and the ground truth labels during training (here we fix real=1 or fake=0). It will calculate the loss for both the generator and the discriminator during backpropagation.\n",
        "\n",
        "\n",
        "During training, the goal is to minimize the BCE loss. This way, the discriminator will learn to correctly classify real and generated samples, while the generator will learn to generate samples that can \"fool\" the discriminator into classifying them as real."
      ],
      "id": "dee6f69b7be9cb0e"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:22.310766Z",
          "start_time": "2025-05-30T08:30:22.308312Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e998f106d2e08636",
        "outputId": "4a6769bf-00b9-4a07-f701-e246f607b95a"
      },
      "cell_type": "code",
      "source": [
        "# real images and discriminator thinks it is real - TRUE POSITIVE\n",
        "target = 1\n",
        "output = 0.99\n",
        "loss = -(target * math.log(output) + (1-target)*math.log(1-output))\n",
        "print(f'TP: {loss}')\n",
        "\n",
        "# real images and discriminator thinks it is fake - TRUE NEGATIVE\n",
        "target = 1\n",
        "output = 0.01\n",
        "loss = -(target * math.log(output) + (1 - target) * math.log(1 - output))\n",
        "print(f'TN: {loss}')\n",
        "\n",
        "# false image but discriminator thinks it is real - FALSE NEGATIVE\n",
        "target = 0\n",
        "output = 0.99\n",
        "loss = -(target * math.log(output) + (1 - target) * math.log(1 - output))\n",
        "print(f'FN: {loss}')"
      ],
      "id": "e998f106d2e08636",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TP: 0.01005033585350145\n",
            "TN: 4.605170185988091\n",
            "FN: 4.605170185988091\n"
          ]
        }
      ],
      "execution_count": 16
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:22.762358Z",
          "start_time": "2025-05-30T08:30:22.759723Z"
        },
        "id": "8d9dfee7e2597870"
      },
      "cell_type": "code",
      "source": [
        "# set real and fake images labels\n",
        "r_label = 0.9\n",
        "f_label = 0\n",
        "\n",
        "# define loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# define optimizers for generator and discriminator\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "id": "8d9dfee7e2597870",
      "outputs": [],
      "execution_count": 17
    },
    {
      "metadata": {
        "id": "856a5ceb101a473a"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "id": "856a5ceb101a473a"
    },
    {
      "metadata": {
        "id": "f27cc0bf67a3c9f2"
      },
      "cell_type": "markdown",
      "source": [
        "To monitor generator's learning progress, we add the constant batch of vectors with noise. During training loop we will feed the generator, and as the training progress we should follow how well the generator transforms these noise into images."
      ],
      "id": "f27cc0bf67a3c9f2"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:23.199214Z",
          "start_time": "2025-05-30T08:30:23.197271Z"
        },
        "id": "4a5eb13c2ca2971e"
      },
      "cell_type": "code",
      "source": [
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)"
      ],
      "id": "4a5eb13c2ca2971e",
      "outputs": [],
      "execution_count": 18
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T08:30:23.625628Z",
          "start_time": "2025-05-30T08:30:23.623457Z"
        },
        "id": "a4722230a490027f"
      },
      "cell_type": "code",
      "source": [
        "show_images = True\n",
        "save_images = True\n",
        "save_model = True\n",
        "\n",
        "def save_dcgan(netG, netD, path_checkpoint):\n",
        "    checkpoint = {\n",
        "        \"g_model_state_dict\": netG.state_dict(),\n",
        "        \"d_model_state_dict\": netD.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, path_checkpoint)\n",
        "    print(f\"Final checkpoint saved at: {path_checkpoint}\")\n",
        "\n",
        "TRAIN_DCGAN_DIR = Path('data/tumors/brain_tumors_img/TrainingGeneratedDCGAN')"
      ],
      "id": "a4722230a490027f",
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": [
        "def create_folder(dst):\n",
        "  if not os.path.exists(dst):\n",
        "        os.makedirs(dst)\n",
        "        print(f'Folder {dst} has been created.')\n",
        "  else:\n",
        "        print(f'Folder {dst} already exists.')\n",
        "\n",
        "create_folder('data/eachEpochImages')\n",
        "create_folder('models/GAN')\n",
        "create_folder('models/tumor_classifier')\n",
        "create_folder('other/gif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhpEWo5qjy6q",
        "outputId": "e779e3b4-f3a9-4494-aa86-7ca8baa43108"
      },
      "id": "JhpEWo5qjy6q",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder data/eachEpochImages already exists.\n",
            "Folder models/GAN already exists.\n",
            "Folder models/tumor_classifier already exists.\n",
            "Folder other/gif has been created.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "543d09e82b1e7b1f"
      },
      "cell_type": "markdown",
      "source": [
        "### Training loop"
      ],
      "id": "543d09e82b1e7b1f"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-30T09:04:10.467398Z",
          "start_time": "2025-05-30T08:50:36.315493Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "54734c4875aebd7f",
        "outputId": "8dd8f3d8-f3e0-4f67-8ab4-680bb627146f"
      },
      "cell_type": "code",
      "source": [
        "data_len = len(train_dataloader) # number of batches\n",
        "\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "D_x_list = []\n",
        "D_G_z1_list = []\n",
        "D_G_z2_list = []\n",
        "\n",
        "# for each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        '''Update D network: maximize log(D(x)) + log(1 - D(G(z)))'''\n",
        "        # train with all real images batch\n",
        "        netD.zero_grad()\n",
        "        # format batch\n",
        "        real_cpu = data[0].to(device)\n",
        "        batch_size = real_cpu.size(0)\n",
        "        label = torch.full((batch_size,), r_label, dtype=torch.float, device=device)\n",
        "        # forward pass through D\n",
        "        output = netD(real_cpu).view(-1)\n",
        "        # calculate loss\n",
        "        errD_real = criterion(output, label)\n",
        "        # calculate gradients for D in backward pass\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        # train with all fake images batch\n",
        "        # generate batch of latent vectors\n",
        "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "        # generate fake image batch with G\n",
        "        fake = netG(noise)\n",
        "        label.fill_(f_label)\n",
        "        # classify all fake batch with D\n",
        "        output = netD(fake.detach()).view(-1)\n",
        "        # calculate D's loss on the all-fake batch\n",
        "        errD_fake = criterion(output, label)\n",
        "        # calculate the gradients for this batch, summed with previous gradients\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # compute error of D as sum over the fake and the real batches\n",
        "        errD = errD_real + errD_fake\n",
        "        # update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        '''Update G network: maximize log(D(G(z)))'''\n",
        "        netG.zero_grad()\n",
        "        label.fill_(r_label) # fake labels are real for generator cost\n",
        "        # since we updated D, perform another forward pass of all-fake batch through D\n",
        "        output = netD(fake).view(-1)\n",
        "        # calculate G's loss based on this output\n",
        "        errG = criterion(output, label)\n",
        "        # calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # update G\n",
        "        optimizerG.step()\n",
        "\n",
        "        ''' Metrics and evaluation'''\n",
        "        # save losses for plots\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "        D_x_list.append(D_x)\n",
        "        D_G_z1_list.append(D_G_z1)\n",
        "        D_G_z2_list.append(D_G_z2)\n",
        "\n",
        "    print(f'Epoch: {epoch+1}/{num_epochs} | Discriminator Loss: {errD.item():.4f} | Generator Loss: {errG:.4f} | D(x): {D_x:.4f} | D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "    # generate fake image samples to see how generator is learning\n",
        "\n",
        "    if show_images == True:\n",
        "        with torch.no_grad():\n",
        "            # uncomment the line below to generate a new variety of images every time\n",
        "            #fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "            fake = netG(fixed_noise).detach().cpu()\n",
        "            img_list.append(utils.make_grid(fake[:9], padding=2, normalize=True, nrow=3))\n",
        "\n",
        "            plt.figure(figsize=(3, 3))\n",
        "            plt.axis('off')\n",
        "            plt.imshow(np.transpose(img_list[-1], (1, 2, 0)))\n",
        "\n",
        "            if save_images == True:\n",
        "                plt.savefig(f'data/eachEpochImages/epoch_{epoch}_gen_images.png')\n",
        "\n",
        "            # Display image\n",
        "            if epoch % 5 == 0:\n",
        "                plt.show()\n",
        "            else:\n",
        "                plt.close()\n",
        "\n",
        "     # Save models each 5 epochs\n",
        "    if epoch % 5 == 0:\n",
        "        if save_model:\n",
        "            save_dcgan(netG, netD, path_checkpoint=f\"models/GAN/tumor_epoch_{epoch}_checkpoint.pkl\")\n",
        "\n",
        "# Save the final models\n",
        "save_dcgan(netG, netD, path_checkpoint=\"models/tumor_final_epoch_checkpoint.pkl\")"
      ],
      "id": "54734c4875aebd7f",
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-12bb5c5ec393>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;34m'''Update D network: maximize log(D(x)) + log(1 - D(G(z)))'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# train with all real images batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-0f6162904784>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;34m\"\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xwI9WLU8sB1_"
      },
      "id": "xwI9WLU8sB1_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Discriminator Output on Real and Fake Images During Training\")\n",
        "plt.plot(D_x_list,label=\"D(x) - real images\")\n",
        "plt.plot(D_G_z1_list, label=\"D(G(z)) before G update\")\n",
        "plt.plot(D_G_z2_list, label=\"D(G(z)) after G update\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Confidence / Probability\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DjWTCvOPt8Bg"
      },
      "id": "DjWTCvOPt8Bg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training process"
      ],
      "metadata": {
        "id": "7h3oGcRI79QS"
      },
      "id": "7h3oGcRI79QS"
    },
    {
      "cell_type": "code",
      "source": [
        "# increase the default limit set by Matplotlib for embedding animations\n",
        "matplotlib.rcParams['animation.embed_limit'] = 500  # 100 MB"
      ],
      "metadata": {
        "id": "weL7GMQ77_Qa"
      },
      "id": "weL7GMQ77_Qa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(6, 6))\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad=2.0, h_pad=2.0, w_pad=2.0)\n",
        "\n",
        "# Initial empty title and image\n",
        "title = plt.title(\"\")\n",
        "img_plot = plt.imshow(np.transpose(img_list[0], (1, 2, 0)), animated=True)\n",
        "\n",
        "def update_title_and_image(frame):\n",
        "    img_plot.set_array(np.transpose(img_list[frame], (1, 2, 0)))\n",
        "    title.set_text(f\"Epoch {frame}/{num_epochs}\")\n",
        "\n",
        "ani = animation.FuncAnimation(fig, update_title_and_image, frames=len(img_list), interval=100, repeat_delay=5000)\n",
        "\n",
        "# Display animation\n",
        "HTML(ani.to_jshtml())"
      ],
      "metadata": {
        "id": "7o_Whffu8ClP"
      },
      "id": "7o_Whffu8ClP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the animation as a GIF\n",
        "ani.save('other/gif/dcgan_training_animation.gif', writer='pillow')"
      ],
      "metadata": {
        "id": "Nn8hB88A8Im6"
      },
      "id": "Nn8hB88A8Im6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}